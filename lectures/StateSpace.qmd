---
title: ""
author: ""
format: 
  revealjs:
    theme: dark
    slide-number: true
    self-contained: true
html-math-method: mathjax
bibliography: book.bib
---

# State-space models {background-color="#33431e"}

Jasper Slingsby

## Latent variables & state-space models {.smaller background-color="#c2c190"}

::: columns
::: {.column width="45%"}
![The iterative ecological forecasting cycle in the context of the scientific method, demonstrating how we stand to learn from making iterative forecasts.](img/ecoforecastingloop.png){width="100%"}
:::

::: {.column width="5%"}
:::

::: {.column width="50%"}
-   Iterative ecological forecasting typically requires modelling variables that vary in time and space...

<br/>

-   State-space models are a general statistical framework that is particularly well-suited to this problem.

<br/>

-   Here I provide a brief introduction to state-space models, but first I must introduce ***latent variables***.
:::
:::

<br>

## Latent variables {background-color="#33431e"}

<br>

Variables are _latent_ if they are unobserved or estimated with uncertainty. 

<br>

- i.e. their true value is not known and can only be inferred indirectly through a model from other variables that can be observed and measured.

## Latent variables {background-color="#33431e"}

<br/>

[Dietze 2017](http://dx.doi.org/10.2307/j.ctvc7796h) outlines 4 common latent variable types:

1. observation errors (random and systematic)
2. proxy data
3. missing data
4. unobserved variables

## Observation error {background-color="#33431e"}

I've already mentioned that a big challenge to modelling is error in the observation of the state variable of interest.

<br/>

Observation errors are typically either:

- ***random***, due to imprecision of the data collection process or other extraneous factors, or

- ***systematic***, implying there is some _bias_


## Precision vs accuracy {background-color="#c2c190"}

::: columns
::: {.column width="55%"}

```{r accuracyprecision, fig.cap='The true value is the origin (0,0).', fig.asp=1, fig.align='left', echo=FALSE, warning=F, message=F}
library(tidyverse)
library(hrbrthemes)

data <- data.frame(set = factor(x = c(rep("precise and accurate", 50), rep("precise, but inaccurate",50), rep("imprecise, but accurate", 50), rep("imprecise and inaccurate", 50)), levels = c("precise and accurate", "precise, but inaccurate", "imprecise, but accurate", "imprecise and inaccurate")), x = c(rnorm(50, mean = 0, sd = 1), rnorm(50, mean = 1.5, sd = 1), rnorm(50, mean = 0, sd = 1.5), rnorm(50, mean = 1.5, sd = 1.5)), y = c(rnorm(50, mean = 0, sd = 1), rnorm(50, mean = 1.5, sd = 1), rnorm(50, mean = 0, sd = 1.5), rnorm(50, mean = 1.5, sd = 1.5)))

data %>%
 # tail(10) %>%
  ggplot(aes(x=x, y=y)) +
    #geom_polygon(fill = "grey") +
    #geom_path(color="black") +
    geom_hline(yintercept = 0) + geom_vline(xintercept = 0) +
    geom_point(shape=21, color="black", fill="#69b3a2", size=3) +
    theme_ipsum(strip_text_size = 25, base_size = 20, axis_title_size = 20) + ylim(-5,5) + xlim(-5,5) +
    facet_wrap(.~set)

```

::: 
::: {.column width="40%"}
<br/>

Imprecision in measurement creates random error.

<br/>

Inaccuracy creates systematic error.
::: 
::: 

## Random observation error {.smaller background-color="#c2c190"}

::: columns
::: {.column width="30%"}

```{r fig.cap='', fig.asp=2, fig.align='left', echo=FALSE, warning=F, message=F}
library(tidyverse)
library(hrbrthemes)

data <- data.frame(set = factor(x = c(rep("precise and accurate", 50), rep("precise, but inaccurate",50), rep("imprecise, but accurate", 50), rep("imprecise and inaccurate", 50)), levels = c("precise and accurate", "precise, but inaccurate", "imprecise, but accurate", "imprecise and inaccurate")), x = c(rnorm(50, mean = 0, sd = 1), rnorm(50, mean = 1.5, sd = 1), rnorm(50, mean = 0, sd = 1.5), rnorm(50, mean = 1.5, sd = 1.5)), y = c(rnorm(50, mean = 0, sd = 1), rnorm(50, mean = 1.5, sd = 1), rnorm(50, mean = 0, sd = 1.5), rnorm(50, mean = 1.5, sd = 1.5)))

data %>%
  filter(set %in% c("precise and accurate", "imprecise, but accurate")) %>%
 # tail(10) %>%
  ggplot(aes(x=x, y=y)) +
    #geom_polygon(fill = "grey") +
    #geom_path(color="black") +
    geom_hline(yintercept = 0) + geom_vline(xintercept = 0) +
    geom_point(shape=21, color="black", fill="#69b3a2", size=5) +
    theme_ipsum(strip_text_size = 35, base_size = 25, axis_title_size = 20) + 
    ylim(-5,5) + xlim(-5,5) +
    facet_wrap(.~set, ncol = 1)

```

::: 
::: {.column width="70%"}

Random error is created by imprecision in measurement ("scatter") around the true state of the variable of interest, but can be created by other processes.

<br/>

In this case we may want to model the true state as a latent variable, and model the random observation error as a probability distribution (typically Gaussian) around the mean.

<br/>

E.g. if we were modelling NDVI (normalised difference vegetation index) from satellite we could specify the **data model** as a normal distribution around the mean ($\mu$):     

$NDVI_{i,t}\sim \mathit{N}(\mu_{i,t},\frac{1}{\sqrt{\tau}}) \\$

Here $\mu$ is the latent variable (estimate of the "true state").

::: 
::::

## Systematic observation error {.smaller background-color="#c2c190"}

::: columns
::: {.column width="30%"}

```{r fig.cap='', fig.asp=2, fig.align='left', echo=FALSE, warning=F, message=F}
library(tidyverse)
library(hrbrthemes)

data <- data.frame(set = factor(x = c(rep("precise and accurate", 50), rep("precise, but inaccurate",50), rep("imprecise, but accurate", 50), rep("imprecise and inaccurate", 50)), levels = c("precise and accurate", "precise, but inaccurate", "imprecise, but accurate", "imprecise and inaccurate")), x = c(rnorm(50, mean = 0, sd = 1), rnorm(50, mean = 1.5, sd = 1), rnorm(50, mean = 0, sd = 1.5), rnorm(50, mean = 1.5, sd = 1.5)), y = c(rnorm(50, mean = 0, sd = 1), rnorm(50, mean = 1.5, sd = 1), rnorm(50, mean = 0, sd = 1.5), rnorm(50, mean = 1.5, sd = 1.5)))

data %>%
  filter(set %in% c("precise, but inaccurate", "imprecise and inaccurate")) %>%
 # tail(10) %>%
  ggplot(aes(x=x, y=y)) +
    #geom_polygon(fill = "grey") +
    #geom_path(color="black") +
    geom_hline(yintercept = 0) + geom_vline(xintercept = 0) +
    geom_point(shape=21, color="black", fill="#69b3a2", size=5) +
    theme_ipsum(strip_text_size = 35, base_size = 25, axis_title_size = 20) + 
    ylim(-5,5) + xlim(-5,5) +
    facet_wrap(.~set, ncol = 1)

```

::: 
::: {.column width="70%"}

Systematic error is where there is a _bias_, such as created by differences among observers or poor instrument calibration.

<br/>

Constant bias can be corrected with an offset, but something like sensor drift may need to be approximated as a random walk or similar (to account for temporal autocorrelation).

<br/>

If we have more information about the causes of error, we can apply more complex observation models (e.g. differences among field staff, temperature dependence of readings, etc).

<br/>

Often there is both random and systematic error, requiring a model that accounts for both.
::: 
::::



## Proxy data {background-color="#33431e"}

I.e. observing a proxy for the state variable of interest, e.g.

- Normalised Difference Vegetation Index (NDVI) for plant cover or vegetation health
- Time-domain reflectometry (TDR) for soil moisture
- Dung as a measure of herbivore habitat preference

There are many ways to relate the _observed_ proxy(ies) to the _latent_ state variable of interest, such as empirical calibration curves, probabilities of identifying dung correctly, etc. 

## Missing data {background-color="#33431e"}

<br/>

Where some observations may be missing from the data, these may be estimated with uncertainty in various ways.

<br/>

Missing data are common in time series or in space (e.g. sensor failure, logistical difficulties, etc.).

## Unobserved variables {background-color="#33431e"}

Some variables may never be observed (e.g too difficult to measure), but can be inferred from the process model, e.g.

- soil stored seedbanks in plant demographic models
- determinants of resource allocation decisions in organisms

<br/>

Estimating these _latent_ variables can be tricky, but having multiple independent measures to constrain the estimates or high confidence in the model structure (i.e. mechanistic understanding) can help.


## State-space models {background-color="#33431e"}

Forecasting involves predicting key variables further in time, and often farther in space.

<br/>

An issue with time-series or spatial modelling is dependence ("autocorrelation") among observations in time and space.

<br/>

One also usually has to deal with a number of latent variables due to missing or sparse data, observation error, etc.



## State-space models {background-color="#33431e"}

_State-space models_ are a useful framework for dealing with these kinds of problems and for forecasting in general.
 
<br/>

The name comes from the focus on estimating the state as a _latent_ variable.

<br/>

This explicitly separates observation errors from process errors, allowing attractive flexibility, including addressing issues of autocorrelation... 


## State-space models {.smaller background-color="#33431e"}

![Illustration of a simple univariate state-space model from [Auger-Methe et al. 2021](https://doi.org/10.1002/ecm.1470).](img/statespace_augermethe.jpg)

a) The dependence among the true (latent) states $z_{t-1}$, $z_t$, $z_{t+1}$, ... can be modeled explicitly in the process model. The dependence of the observations $y_t$ on the states $z_t$ allows observations to be assumed to be independent. 

b) State estimates can be closer to the true states than the observations.


## State-space models - example {.smaller background-color="#33431e"}

Here's an SSM where the process model is a random walk (i.e. change at each time step is just process error ($\tau_{add}$) - a random draw from a normal distribution). We've also specified a data model with observation error drawn from a normal distribution.

<br/>

The process model[^1]: $$z_{t+1}\sim\mathit{N}(z_{t},\tau_{add})$$

The data model: $$y_{t}\sim\mathit{N}(z_{t},\tau_{obs})$$

<br/>

For a Bayesian model this would also require priors on the process error ($\tau_{add}$), observation error ($\tau_{obs}$) and initial condition of the state variable ($z_0$).

[^1]: Note that the process and data model can also be referred to as the _state_ and _observation_ models respectively.

## State-space models - example {.smaller background-color="#33431e"}

<br/>

The probability distribution for the state variable, $z_{t}$, conditional on the model parameters would be:

$$
\underbrace{z_{t}|...}_\text{current state} \; \propto \; \underbrace{ {\mathit{N}(z_{t}|z_{t-1},\tau_{add})}}_\text{previous time} \; \underbrace{ {\mathit{N}(y_{t}|z_{t},\tau_{obs})}}_\text{current observation} \; \underbrace{ {\mathit{N}(z_{t+1}|z_{t},\tau_{add})}}_\text{next time} \;
$$


Which says that the current state ($z_{t}$) depends on both the states before and after as well as the current observation ($y_{t}$).

<br/>

In fact, the posterior of the current state ($z_{t}$) is proportional to the product of the three normal distributions.

## State-space models - example {.smaller background-color="#33431e"}

$$
\underbrace{z_{t}|...}_\text{current state} \; \propto \; \underbrace{ {\mathit{N}(z_{t}|z_{t-1},\tau_{add})}}_\text{previous time} \; \underbrace{ {\mathit{N}(y_{t}|z_{t},\tau_{obs})}}_\text{current observation} \; \underbrace{ {\mathit{N}(z_{t+1}|z_{t},\tau_{add})}}_\text{next time} \;
$$

```{r, echo = F, fig.width = 7, fig.asp = 0.5, fig.align='center'}
library(tidyverse)

rangeP <- seq(0, 1, length.out = 100)

prev <- dnorm(x = rangeP, mean = .5, sd = .1)
obs <- dnorm(x = rangeP, mean = .6, sd = .1)
nex <- dnorm(x = rangeP, mean = .7, sd = .1)

dat <- data.frame(
  term = factor(c(rep("current state", 100), rep("previous time", 100), rep("current observation", 100), rep("next time", 100)),
                levels = c("current state", "previous time", "current observation", "next time")),
  state = rep(rangeP,4),
  Density = c(prev*obs*nex/sum(prev,obs,nex), prev/30, obs/30, nex/30)
    )

ggplot(dat, aes(y = Density, x = state)) +
  geom_line() +
  facet_wrap(. ~ term, nrow = 1) +
  coord_flip()

```

Where the terms are similar, the state estimate peaks, indicating less uncertainty.

## State-space models - example {.smaller background-color="#33431e"}

$$
\underbrace{z_{t}|...}_\text{current state} \; \propto \; \underbrace{ {\mathit{N}(z_{t}|z_{t-1},\tau_{add})}}_\text{previous time} \; \underbrace{ {\mathit{N}(y_{t}|z_{t},\tau_{obs})}}_\text{current observation} \; \underbrace{ {\mathit{N}(z_{t+1}|z_{t},\tau_{add})}}_\text{next time} \;
$$

```{r, echo = F, fig.width = 7, fig.asp = 0.5, fig.align='center'}
library(tidyverse)

rangeP <- seq(0, 1, length.out = 100)

prev <- dnorm(x = rangeP, mean = .5, sd = .1)
obs <- dnorm(x = rangeP, mean = .65, sd = .1)
nex <- dnorm(x = rangeP, mean = .8, sd = .1)

dat <- data.frame(
  term = factor(c(rep("current state", 100), rep("previous time", 100), rep("current observation", 100), rep("next time", 100)),
                levels = c("current state", "previous time", "current observation", "next time")),
  state = rep(rangeP,4),
  Density = c(prev*obs*nex/sum(prev,obs,nex), prev/30, obs/30, nex/30)
    )

ggplot(dat, aes(y = Density, x = state)) +
  geom_line() +
  facet_wrap(. ~ term, nrow = 1) +
  coord_flip()

```

Where the terms differ, the state estimate flattens, indicating greater uncertainty.

## State-space models - example {.smaller background-color="#33431e"}


$$
\underbrace{z_{t}|...}_\text{current state} \; \propto \; \underbrace{ {\mathit{N}(z_{t}|z_{t-1},\tau_{add})}}_\text{previous time} \; \underbrace{ {\mathit{N}(y_{t}|z_{t},\tau_{obs})}}_\text{current observation} \;
$$

```{r, echo = F, fig.width = 7, fig.asp = 0.5, fig.align='center'}
library(tidyverse)

rangeP <- seq(0, 1, length.out = 100)

prev <- dnorm(x = rangeP, mean = .5, sd = .1)
obs <- dnorm(x = rangeP, mean = .6, sd = .1)

dat <- data.frame(
  term = factor(c(rep("current state", 100), rep("previous time", 100), rep("current observation", 100)),
                levels = c("current state", "previous time", "current observation")),
  state = rep(rangeP,3),
  Density = c(prev*obs/sum(prev,obs), prev/30, obs/30)
    )

ggplot(dat, aes(y = Density, x = state)) +
  geom_line() +
  facet_wrap(. ~ term, nrow = 1) +
  coord_flip()

```

Usually, there's no observation for "next time", and the model reduces to...

## State-space models - example {.smaller background-color="#33431e"}

::: columns
::: {.column width="60%"}

There's no "current observation" for forecasts, so:

$$
\underbrace{z_{t}|...}_\text{forecast state} \; \propto \; \underbrace{ {\mathit{N}(z_{t}|z_{t-1},\tau_{add})}}_\text{previous time} \; 
$$

```{r, echo = F, fig.width = 7, fig.asp = 0.5, fig.align='center'}
library(tidyverse)

rangeP <- seq(0, 1, length.out = 100)

prev <- dnorm(x = rangeP, mean = .5, sd = .1)
fore <- dnorm(x = rangeP, mean = .5, sd = .1)

dat <- data.frame(
  term = factor(c(rep("forecast state", 100), rep("previous time", 100)),
                levels = c("forecast state", "previous time")),
  state = rep(rangeP,2),
  Density = c(fore/sum(fore), prev/30)
    )

ggplot(dat, aes(y = Density, x = state)) +
  geom_line() +
  facet_wrap(. ~ term, nrow = 1) +
  coord_flip()

```

::: 
::: {.column width="35%"}

<br/>

In this dummy model the forecast is almost exactly the same as the previous time, because the process model is a random walk and simply adds a little error ($\tau_{add}$) to the previous state ($z_{t-1}$).

:::
::::


## A more interesting example? {.smaller background-color="#33431e"}

```{r fynbos, echo=FALSE, fig.cap = "", fig.width=3, fig.align = 'center', out.width="80%"}
knitr::include_graphics("img/CFR_Seasonality.gif")
```

Time-series of the Normalised Difference Vegetation Index (NDVI ~ vegetation "greenness" measured from the MODIS satellites) to look at vegetation recovery with time since fire in Fynbos.

## State-space models - postfire {.smaller background-color="#33431e"}

```{r postfire_nocurve, echo=FALSE, fig.cap = "", fig.width=3, fig.align = 'center', out.width="50%"}
knitr::include_graphics("img/postfire_nocurve.png")
```

NDVI in Fynbos does not follow a random walk, but rather a curve that increases rapidly after fire, then slows down as it approaches a maximum value.


## State-space models - postfire {.smaller background-color="#33431e"}

```{r postfire_negexp, echo=FALSE, fig.cap = "", fig.width=3, fig.align = 'center', out.width="50%"}
knitr::include_graphics("img/postfire_negexp.png")
```

We can model the post-fire recovery curve is an intercept (greeness immediately after fire) plus a negative exponential, where the vegetation greenness (NDVI) increases rapidly after fire, but then slows down as it approaches a maximum value.

\begin{gather}
  \text{NDVI}_{i,t}=\alpha_i+\gamma_i\Big(1-e^{-\frac{age_{i,t}}{\lambda_i}}\Big)
\end{gather}

## State-space models - postfire {.smaller background-color="#33431e"}

```{r postfire_negexp_seasonality, echo=FALSE, fig.cap = "", fig.width=3, fig.align = 'center', out.width="40%"}
knitr::include_graphics("img/postfire_negexp_seasonality.png")
```

We can also account for seasonality by adding a sine term

\begin{gather}
  \text{NDVI}_{i,t}=\alpha_i+\gamma_i\Big(1-e^{-\frac{age_{i,t}}{\lambda_i}}\Big)+
      A_i\text{sin}\Big(2\pi\times\text{age}_{i,t}+\Big[\phi+\frac{\pi}{6}(m_{i,t}-1)\Big]\Big)
\end{gather}

## A quick aside on the parameters {.smaller background-color="#c2c190"}

\begin{gather}
  \text{NDVI}_{i,t}=\alpha_i+\gamma_i\Big(1-e^{-\frac{age_{i,t}}{\lambda_i}}\Big)+
      A_i\text{sin}\Big(2\pi\times\text{age}_{i,t}+\Big[\phi+\frac{\pi}{6}(m_{i,t}-1)\Big]\Big)
\end{gather}

::: columns

::: {.column width="50%"}

```{r}
knitr::include_graphics("img/postfire_negexp_seasonality.png")
```

:::

::: {.column width="45%"}

-   $\alpha$ is the NDVI at time 0 
    - i.e. directly after the fire
-   $\gamma$ is the maximum *increase* in NDVI
    -   i.e. the maximum average NDVI reached by the curve is $\alpha + \gamma$
-   $\lambda$ is the rate of increase in NDVI
-   $A$ is the amplitude of the sine term
-   $\phi$ adjusts the timing of the sine term based on the month the fire occurred
-   $m$ is the month that the fire occurred

:::
:::

## State-space models - postfire {.smaller background-color="#33431e"}

Our postfire recovery example could use a state update equation with process model:

$$x_{i,t} = \underbrace{(x_{i,t-1} + x_{i,t-1}\lambda_i(1-\frac{x_{i,t-1}}{\gamma_i}))}_\text{negative exponential} \underbrace{(1-z_{i,t-1})}_\text{fire occurrence} + \underbrace{z_{i,t-1}\alpha_i}_\text{postfire greeness} +  \underbrace{A_i\sin(v_t+\phi_i)}_\text{seasonality} +  \epsilon_{i,t}$$
and data model (as before):

$$NDVI_{i,t} \sim \mathit{N}(x_{i,t},\sigma_o^{2})$$

$x_{i,t}$ is the hidden state for site $i$ at time $t$  

$z_{i,t}$ is the observed occurrence of fire (0/1)

The process model ("previous time" only) represents negative exponential growth, seasonality and a fire switch that tells the model to follow the exponential when fires do not occur ($z_{i,t} = 0$) or resets the state to postfire greenness ($\alpha$) when they do ($z_{i,t} = 1$).

## State-space models - postfire {.smaller background-color="#33431e"}

![](img/statespace_Slingsby2023.png)

from [Slingsby et al. 2023](http://dx.doi.org/10.1111/2041-210x.14046)


## State-space models - uses {background-color="#33431e"}

They can be used for almost anything where the future state of a system depends on the current state, including:

- population dynamics
- fisheries stock assessment
- movement ecology (biologging)
- capture-recapture
- epidemiology and disease ecology
- weather, carbon cycle, etc, etc


## State-space models - uses {background-color="#33431e"}

Also referred to as _Hidden Markov models_

- "hidden" refers to the latent variable(s) 
- "Markov" refers to their recursive nature,  with the next state in time a function of the current state

When extended to spatial or space-time models they are sometimes called _Markov random fields_


## References {.smaller background-color="#33431e"}

Auger-Méthé, Marie, Ken Newman, Diana Cole, Fanny Empacher, Rowenna Gryba, Aaron A. King, Vianey Leos-Barajas, et al. 2021. “A Guide to State–space Modeling of Ecological Time Series.” Ecological Monographs 91 (4): e01470. https://doi.org/10.1002/ecm.1470.

Dietze, Michael C. 2017. Ecological Forecasting. Princeton University Press. https://doi.org/10.2307/j.ctvc7796h. - especially Ch 8 _Latent Variables and State-Space Models_

Slingsby, Jasper A., Adam M. Wilson, Brian Maitner, and Glenn R. Moncrieff. 2023. “Regional Ecological Forecasting across Scales: A Manifesto for a Biodiversity Hotspot.” Methods in Ecology and Evolution / British Ecological Society, January. https://doi.org/10.1111/2041-210x.14046.
